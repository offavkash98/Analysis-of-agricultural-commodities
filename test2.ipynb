{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv(\"azureml://subscriptions/4f93438e-847c-469d-94ae-ef5ee130ccab/resourcegroups/project_team14/workspaces/mlnotebook/datastores/testml/paths/Final_Data/part-00000-tid-1107757838746000038-dd6987f9-5526-4378-b9fd-633c8f0e2565-1388-1-c000.csv\")\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "  Commodity         State Name District Name         Market Name Variety  \\\n0    Papaya                Goa     North Goa              Mapusa  Papaya   \n1    Papaya  Jammu and Kashmir         Jammu  Narwal Jammu (F&V)   Other   \n2    Papaya       NCT of Delhi         Delhi            Shahdara   Other   \n3    Papaya             Punjab      Bhatinda            Bathinda   Other   \n4    Papaya             Punjab      Ferozpur      Firozepur City   Other   \n\n    Group  Arrivals (Tonnes)  Min Price (Rs/Quintal)  Max Price (Rs/Quintal)  \\\n0  Fruits               1.33                  2400.0                  3600.0   \n1  Fruits              12.00                  1150.0                  1250.0   \n2  Fruits               0.10                   150.0                   300.0   \n3  Fruits               4.50                   400.0                   450.0   \n4  Fruits              10.00                   600.0                   800.0   \n\n   Modal Price (Rs/Quintal) Reported Date  \n0                    3000.0    2003-04-01  \n1                    1200.0    2003-04-01  \n2                     250.0    2003-04-02  \n3                     425.0    2003-04-01  \n4                     700.0    2003-04-02  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Commodity</th>\n      <th>State Name</th>\n      <th>District Name</th>\n      <th>Market Name</th>\n      <th>Variety</th>\n      <th>Group</th>\n      <th>Arrivals (Tonnes)</th>\n      <th>Min Price (Rs/Quintal)</th>\n      <th>Max Price (Rs/Quintal)</th>\n      <th>Modal Price (Rs/Quintal)</th>\n      <th>Reported Date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Papaya</td>\n      <td>Goa</td>\n      <td>North Goa</td>\n      <td>Mapusa</td>\n      <td>Papaya</td>\n      <td>Fruits</td>\n      <td>1.33</td>\n      <td>2400.0</td>\n      <td>3600.0</td>\n      <td>3000.0</td>\n      <td>2003-04-01</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Papaya</td>\n      <td>Jammu and Kashmir</td>\n      <td>Jammu</td>\n      <td>Narwal Jammu (F&amp;V)</td>\n      <td>Other</td>\n      <td>Fruits</td>\n      <td>12.00</td>\n      <td>1150.0</td>\n      <td>1250.0</td>\n      <td>1200.0</td>\n      <td>2003-04-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Papaya</td>\n      <td>NCT of Delhi</td>\n      <td>Delhi</td>\n      <td>Shahdara</td>\n      <td>Other</td>\n      <td>Fruits</td>\n      <td>0.10</td>\n      <td>150.0</td>\n      <td>300.0</td>\n      <td>250.0</td>\n      <td>2003-04-02</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Papaya</td>\n      <td>Punjab</td>\n      <td>Bhatinda</td>\n      <td>Bathinda</td>\n      <td>Other</td>\n      <td>Fruits</td>\n      <td>4.50</td>\n      <td>400.0</td>\n      <td>450.0</td>\n      <td>425.0</td>\n      <td>2003-04-01</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Papaya</td>\n      <td>Punjab</td>\n      <td>Ferozpur</td>\n      <td>Firozepur City</td>\n      <td>Other</td>\n      <td>Fruits</td>\n      <td>10.00</td>\n      <td>600.0</td>\n      <td>800.0</td>\n      <td>700.0</td>\n      <td>2003-04-02</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1708082713667
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: tensorflow in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (2.13.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (0.32.0)\nRequirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (2.3.0)\nRequirement already satisfied: keras<2.14,>=2.13.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (2.13.1)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (0.4.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: tensorboard<2.14,>=2.13 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.54.2)\nRequirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (23.0)\nRequirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (2.13.0)\nRequirement already satisfied: h5py>=2.9.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: absl-py>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: numpy<=1.24.3,>=1.22 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.24.3)\nRequirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (4.5.0)\nRequirement already satisfied: wrapt>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (4.25.3)\nRequirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.16.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (65.6.3)\nRequirement already satisfied: astunparse>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.1.21 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (23.5.9)\nRequirement already satisfied: libclang>=13.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorflow) (16.0.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.2)\nRequirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.4)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.18.1)\nRequirement already satisfied: wheel>=0.26 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.37.1)\nRequirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (6.6.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.9.24)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (1.26.16)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.5)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\nRequirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.12.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\nRequirement already satisfied: pyasn1>=0.1.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "\n",
        "# Assuming 'Reported Date' is a datetime column, convert it to datetime\n",
        "df['Reported Date'] = pd.to_datetime(df['Reported Date'])\n",
        "\n",
        "# Randomly shuffle the data\n",
        "data = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split the data into 5 equal samples\n",
        "data_samples = []\n",
        "split_size = len(data) // 5\n",
        "for i in range(5):\n",
        "    start_index = i * split_size\n",
        "    end_index = (i + 1) * split_size if i < 4 else None\n",
        "    data_samples.append(data.iloc[start_index:end_index])\n",
        "\n",
        "# Define function to create LSTM model\n",
        "def create_lstm_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, input_shape=input_shape))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Train LSTM model for each sample\n",
        "models = []\n",
        "for i, sample in enumerate(data_samples):\n",
        "    # Preprocessing: normalize the features\n",
        "    scaler = MinMaxScaler()\n",
        "    scaled_data = scaler.fit_transform(sample[['Arrivals (Tonnes)', 'Min Price (Rs/Quintal)', 'Max Price (Rs/Quintal)', 'Modal Price (Rs/Quintal)']])\n",
        "    X = scaled_data[:, :-1]  # Use all features except 'Modal Price' as input\n",
        "    y = scaled_data[:, -1]   # Use 'Modal Price' as target\n",
        "\n",
        "    # Reshape input data to be 3D [samples, timesteps, features]\n",
        "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Create LSTM model\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "    lstm_model = create_lstm_model(input_shape)\n",
        "\n",
        "    # Train the model\n",
        "    lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    # Evaluate the model\n",
        "    loss = lstm_model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Sample {i+1} Loss: {loss}\")\n",
        "\n",
        "    # Save the model\n",
        "    models.append(lstm_model)\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'keras'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LSTM, Dense\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708080022755
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Assuming you have loaded your dataset into a DataFrame called 'df'\n",
        "\n",
        "# Drop any non-numeric columns or columns that can't be used for modeling\n",
        "# For instance, if 'Reported Date' isn't relevant for prediction, you might drop it\n",
        "df_numeric = df.drop(['Commodity', 'State Name', 'District Name', 'Market Name', 'Variety', 'Group', 'Reported Date'], axis=1)\n",
        "\n",
        "# Encode categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "for column in [ 'State Name', 'District Name', 'Market Name', 'Variety', 'Group']:\n",
        "    df_numeric[column] = label_encoder.fit_transform(df_numeric[column])\n",
        "\n",
        "# Split the data into features (X) and target variable (y)\n",
        "X = df_numeric.drop('Modal Price (Rs/Quintal)', axis=1)\n",
        "y = df_numeric['Modal Price (Rs/Quintal)']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "predictions = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'State Name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'State Name'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m label_encoder \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m column \u001b[38;5;129;01min\u001b[39;00m [ \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mState Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMarket Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVariety\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m---> 16\u001b[0m     df_numeric[column] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mdf_numeric\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Split the data into features (X) and target variable (y)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m X \u001b[38;5;241m=\u001b[39m df_numeric\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModal Price (Rs/Quintal)\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m/anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'State Name'"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708082093401
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_com=df['Commodity']"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708082805173
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict_com=pd.DataFrame(dict_com.unique())"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708082899148
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dict_com.count()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "0    297\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1708082926793
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_numeric[column] = label_encoder.fit_transform(df_numeric[column])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}