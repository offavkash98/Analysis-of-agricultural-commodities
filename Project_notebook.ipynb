{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "851e01e6-07f3-4064-9c97-3b8b0521b324",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col from pyspark.sql.types import IntegerType, DoubleType, BooleanType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe680af1-ccc7-46bf-ad25-44aa16f50535",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs = {\"fs.azure.account.auth.type\": \"OAuth\", \"fs.azure.account.oauth.provider.type\": \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\", \"fs.azure.account.oauth2.client.id\": \"85bca2ca-4f4f-4401-89b1-71e1f0fea20c\", \"fs.azure.account.oauth2.client.secret\": 'WKa8Q~rS5RSj28rWu3fzI5Td9VdtLNAxxuNzmdnY', \"fs.azure.account.oauth2.client.endpoint\": \"https://login.microsoftonline.com/174b0b5b-33bb-4f51-b829-91a9306542d1/oauth2/token\"} \n",
    "dbutils.fs.mount( \n",
    "    source = \"abfss://project-dataset@cdacprojectteam14.dfs.core.windows.net\", \n",
    "    # contrainer@storageacc \n",
    "    mount_point = \"/mnt/projectteam14\", extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce096663-f935-49db-906d-efacadc5c8bb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/mnt/projectteam14/Final_Data.csv</td><td>Final_Data.csv</td><td>5608944911</td><td>1707645802000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/mnt/projectteam14/Final_Data.csv",
         "Final_Data.csv",
         5608944911,
         1707645802000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs \n",
    "ls \"/mnt/projectteam14\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8539b752-a1eb-433f-afa2-f61b4bbc490e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=5135074789704077#setting/sparkui/0211-191227-t9zp177o/driver-5848814189648164377\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*, 4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f24b1b5f640>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c97717b3-7601-4c3b-a31d-7952a0b68d5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").load(\"/mnt/projectteam14/Final_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2dbb41ee-4d7f-456c-b006-d7cd6dd5f3bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----------+-------------+-----------+-------------+------+-----------------+--------------------+--------------------+--------------------+-------------+------------+----------+\n| _c0|         _c1|       _c2|          _c3|        _c4|          _c5|   _c6|              _c7|                 _c8|                 _c9|                _c10|         _c11|        _c12|      _c13|\n+----+------------+----------+-------------+-----------+-------------+------+-----------------+--------------------+--------------------+--------------------+-------------+------------+----------+\n|NULL|   Commodity|State Name|District Name|Market Name|      Variety| Group|Arrivals (Tonnes)|Min Price (Rs./Qu...|Max Price (Rs./Qu...|Modal Price (Rs./...|Reported Date|Unnamed: 0.1|Unnamed: 0|\n|   0|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|              0.5|              5500.0|                5905|              5705.0|  04 Apr 2017|        NULL|      NULL|\n|   1|ChennangiDal|   Gujarat|        Surat|    Songadh|   Gram Chapa|Pulses|              1.1|              3560.0|                3965|              3775.0|  04 Apr 2018|        NULL|      NULL|\n|   2|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             17.0|              4600.0|                5200|              4900.0|  04 Jan 2020|        NULL|      NULL|\n|   3|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|              0.2|              4300.0|                4345|              4325.0|  03 Mar 2016|        NULL|      NULL|\n|   4|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             17.0|              5800.0|                6500|              6150.0|  04 Mar 2016|        NULL|      NULL|\n|   5|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|              4.0|              5800.0|                6500|              6150.0|  03 Mar 2016|        NULL|      NULL|\n|   6|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             42.0|              5800.0|                6500|              6150.0|  02 Mar 2016|        NULL|      NULL|\n|   7|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             52.0|              5800.0|                6500|              6150.0|  01 Mar 2016|        NULL|      NULL|\n|   8|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|              3.4|              5335.0|                5695|              5515.0|  04 May 2017|        NULL|      NULL|\n|   9|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|              6.3|              5135.0|                5500|              5317.0|  03 May 2017|        NULL|      NULL|\n|  10|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             12.0|              5600.0|                6000|              5700.0|  04 May 2017|        NULL|      NULL|\n|  11|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             15.0|              5600.0|                6000|              5700.0|  03 May 2017|        NULL|      NULL|\n|  12|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             14.0|              5200.0|                6000|              5600.0|  04 May 2019|        NULL|      NULL|\n|  13|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             79.0|              5200.0|                6000|              5600.0|  03 May 2019|        NULL|      NULL|\n|  14|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             71.0|              5200.0|                6000|              5600.0|  02 May 2019|        NULL|      NULL|\n|  15|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             42.0|              1000.0|                1200|              1100.0|  05 Aug 2003|        NULL|      NULL|\n|  16|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             26.0|              4050.0|                4200|              4100.0|  05 Jul 2012|        NULL|      NULL|\n|  17|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|             0.10|              5650.0|                5650|              5650.0|  04 Jun 2016|        NULL|      NULL|\n|  18|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|                 |              6000.0|                6000|              6000.0|  03 Jun 2016|        NULL|      NULL|\n+----+------------+----------+-------------+-----------+-------------+------+-----------------+--------------------+--------------------+--------------------+-------------+------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a34595b3-4539-448c-825d-04230aaca83e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('_c0', 'string'),\n",
       " ('_c1', 'string'),\n",
       " ('_c2', 'string'),\n",
       " ('_c3', 'string'),\n",
       " ('_c4', 'string'),\n",
       " ('_c5', 'string'),\n",
       " ('_c6', 'string'),\n",
       " ('_c7', 'string'),\n",
       " ('_c8', 'string'),\n",
       " ('_c9', 'string'),\n",
       " ('_c10', 'string'),\n",
       " ('_c11', 'string'),\n",
       " ('_c12', 'string'),\n",
       " ('_c13', 'string')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b5f9b39-8e4e-4ad3-b21c-d4836f8339cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+----------+-------------+-----------+-------------+------+-----------------+--------------------+--------------------+--------------------+-------------+------------+----------+\n| _c0|         _c1|       _c2|          _c3|        _c4|          _c5|   _c6|              _c7|                 _c8|                 _c9|                _c10|         _c11|        _c12|      _c13|\n+----+------------+----------+-------------+-----------+-------------+------+-----------------+--------------------+--------------------+--------------------+-------------+------------+----------+\n|NULL|   Commodity|State Name|District Name|Market Name|      Variety| Group|Arrivals (Tonnes)|Min Price (Rs./Qu...|Max Price (Rs./Qu...|Modal Price (Rs./...|Reported Date|Unnamed: 0.1|Unnamed: 0|\n|   0|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|              0.5|              5500.0|                5905|              5705.0|  04 Apr 2017|        NULL|      NULL|\n|   1|ChennangiDal|   Gujarat|        Surat|    Songadh|   Gram Chapa|Pulses|              1.1|              3560.0|                3965|              3775.0|  04 Apr 2018|        NULL|      NULL|\n|   2|ChennangiDal| Karnataka|    Bangalore|  Bangalore|Chennangi Dal|Pulses|             17.0|              4600.0|                5200|              4900.0|  04 Jan 2020|        NULL|      NULL|\n|   3|ChennangiDal|   Gujarat|        Surat|    Songadh|        Other|Pulses|              0.2|              4300.0|                4345|              4325.0|  03 Mar 2016|        NULL|      NULL|\n+----+------------+----------+-------------+-----------+-------------+------+-----------------+--------------------+--------------------+--------------------+-------------+------------+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bc417f-2dfd-46b1-bd4b-8cac7c88e906",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-2886894467639094>, line 1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misNull\u001B[49m()\u001B[38;5;241m.\u001B[39mcount()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3068\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n",
       "\u001B[1;32m   3035\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001B[39;00m\n",
       "\u001B[1;32m   3036\u001B[0m \n",
       "\u001B[1;32m   3037\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m   3065\u001B[0m \u001B[38;5;124;03m+---+\u001B[39;00m\n",
       "\u001B[1;32m   3066\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m   3067\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n",
       "\u001B[0;32m-> 3068\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n",
       "\u001B[1;32m   3069\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name)\n",
       "\u001B[1;32m   3070\u001B[0m     )\n",
       "\u001B[1;32m   3071\u001B[0m jc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mapply(name)\n",
       "\u001B[1;32m   3072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(jc)\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'isNull'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\nFile \u001B[0;32m<command-2886894467639094>, line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43misNull\u001B[49m()\u001B[38;5;241m.\u001B[39mcount()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:3068\u001B[0m, in \u001B[0;36mDataFrame.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m   3035\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001B[39;00m\n\u001B[1;32m   3036\u001B[0m \n\u001B[1;32m   3037\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   3065\u001B[0m \u001B[38;5;124;03m+---+\u001B[39;00m\n\u001B[1;32m   3066\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   3067\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns:\n\u001B[0;32m-> 3068\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m   3069\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name)\n\u001B[1;32m   3070\u001B[0m     )\n\u001B[1;32m   3071\u001B[0m jc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jdf\u001B[38;5;241m.\u001B[39mapply(name)\n\u001B[1;32m   3072\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m Column(jc)\n\n\u001B[0;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'isNull'",
       "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'DataFrame' object has no attribute 'isNull'",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.a"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 186167719292630,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Project_notebook",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
